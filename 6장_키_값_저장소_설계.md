# 6장: 키-값 저장소 설계

## 쓰기/읽기 작업 흐름
### 쓰기 작업
* 쓰기는 하나의 노드에서 커멘드 로그를 남긴 후, 메모리에 쓰기 발생
* 디스크에 반영은 일정 시간 간격 또는 일정량의 데이터 쓰기가 발생한 이후, flush
* 정족수 합의를 통해 다중화할 경우: 리더에서 레플리카들에 쓰기 전파 -> 레플리카들에서 동일한 방식으로 커맨드 로그 남기고, 메모리 쓰기 일어난 후에 ACK 응답 -> 쓰기 확정

### 읽기 작업
* 읽기 요청은 먼저 메모리를 조회하고 메모리에 없을 경우, 디스크에 데이터가 있는지 확인
* 이때, 블룸 필터(데이터를 일정 단위로 분리 -> 해싱 -> 모듈 연산 통해 얻은 인덱스를 토대로 배열[인덱스]=1로 해당 컴포넌트 존재함을 나타냄)를 활용하여 데이터 유무를 빠르게 확인(데이터 없음은 정확히 판단하고, 데이터 있음은 틀릴 수 있음. 왜냐하면 다른 데이터들을 통해 해당 조합의 배열 위치가 1로 나타날 수 있음)를 통해 데이터 유무 빠르게 판단
* 이후 데이터 조회해서 메모리에 캐싱하고 유저에게 반환

## 확장 가능한 고가용성 키-값 저장소 설계를 위해 고려해야 할 컴포넌트들
* 이 장은 확장 가능한 키-값 저장소 설계를 목표로 함
* 확장 가능한 키-값 저장소 설계를 위해 아래 내용들을 고려해야 함
    * 대규모 데이터 저장이 가능할 것
    * 서버 장애를 감지할 것
    * CAP 이론 선택
    * 서버 장애에 대응할 것
    * 데이터 충돌에 대응할 것
    * 데이터 유실 방지할 것
    * 서버 증감이 자유로울 것

### 대규모 데이터 저장이 가능할 것
* 자주 조회되는 데이터는 메모리, 그렇지 않은 데이터는 디스크에 저장
* 샤딩을 통해 분산 저장: 안정 해싱을 통해 균등 분배 및 서버 증감 시, 데이터 이동 최소화

### 서버 장애를 감지할 것
* 분산 서버에서 서로의 장애를 감지: 하트비트, 가십 프로토콜
* 서버는 현존하는 멤버들의 리스트를 가짐. 리스트에는 각 서버의 하트 비트 포함됨
* 일정 시간마다 하트 비트 업데이트하고 가십 프로토콜로 임의의 n개의 서버에게 멤버 리스트 전송
* 멤버 리스트 받은 서버는 자신이 알고 있는 각 서버의 하트비트보다 큰 값이 들어오면 반영

### CAP 이론 선택
* 네트워크 분할이 발생했을때, 일관성과 가용성 중 무엇을 선택할 건지
* 금융과 같은 엄격한 정합성을 요구하는 도메인이 아니면 AP 모델 선택
* 하나의 서버에 장애가 발생해도 다른 서버에서 데이터 업데이트가 발생할 수 있어야 함

### 서버 장애에 대응할 것
* 서버 장애 시, 해당 서버가 다시 시작할동안 다른 서버에서 발생한 변경사항을 모아서 동기화해야 함
* 일시적 동기화: 힌트 후, 임시 위탁 방식(해당 서버 장애 후, 발생한 변경사항 남기기)
* 영구 동기화: 머클 트리(해싱 값을 통해 변경된 데이터 빠른 탐색)

### 데이터 충돌에 대응할 것
* 여러 클라이언트가 서로 다른 노드로 동일한 데이터 수정을 하려는 상황에서 충돌의 위험이 있음
* 충돌을 방지하기 위해 락을 사용하면 성능 저하 발생
* 버저닝을 통해 각 노드에 다른 버전의 데이터가 존재하는 것을 허용하고 조회 시, 클라이언트가 충돌 관리해야 함
* 리더-레플리카 구조에서는 리더에만 쓰기가 발생하기 때문에 해당 문제가 없지만, 아마존 dynamo와 같은 저장소에서는 다수의 노드에 병렬 쓰기를 허용함

### 데이터 유실 방지할 것
* 데이터를 다중화하여 해시링에서 처음 마주치는 n개의 노드에 쓰기가 일어나도록 함
* 데이터를 여러 데이터 센터에 다중화함으로써 데이터 센터의 장애에 대응
* 이때, 가상 노드 n개를 고르면 실제 저장은 n개 미만에서 발생할 수 있기 때문에, 실제 저장되는 노드 수 고려하기
* 정족수 합의: 쓰기/읽기가 완료되기 위해 일정 개수의 노드로부터 응답을 받아야 함

### 서버 증감이 자유로울 것
* 안정 해시를 이용하고, 해시 링 위 여러 지점에 가상 노드가 위치하게 함으로써 서버 증감 상황에서 이동해야 할 데이터를 최소화하고 균등한 데이터 분배가 가능함